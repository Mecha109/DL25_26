================================================================================
SUMMARY OF ALL CONFIGURATIONS
================================================================================
Hidden   LR       Dropout  L2       Train Acc  Val Acc    Test Acc  
--------------------------------------------------------------------------------
16       0.1      0.0      0.0      0.0563     0.0866     0.0560
16       0.1      0.0      0.0001   0.0385     0.0461     0.0385
16       0.1      0.1      0.0      0.0385     0.0600     0.0385
16       0.1      0.1      0.0001   0.0385     0.0651     0.0385
16       0.01     0.0      0.0      0.7572     0.7458     0.7366
16       0.01     0.0      0.0001   0.7252     0.7303     0.7166
16       0.01     0.1      0.0      0.7287     0.7250     0.7124
16       0.01     0.1      0.0001   0.7109     0.7233     0.7047
16       0.001    0.0      0.0      0.7767     0.7619     0.7678
16       0.001    0.0      0.0001   0.7854     0.7798     0.7766
16       0.001    0.1      0.0      0.7670     0.7602     0.7562
16       0.001    0.1      0.0001   0.7662     0.7544     0.7559
16       0.0001   0.0      0.0      0.7197     0.7164     0.7146
16       0.0001   0.0      0.0001   0.7196     0.7144     0.7150
16       0.0001   0.1      0.0      0.7139     0.7108     0.7109
16       0.0001   0.1      0.0001   0.7244     0.7235     0.7225
32       0.1      0.0      0.0      0.0488     0.0603     0.0483
32       0.1      0.0      0.0001   0.0385     0.0698     0.0385
32       0.1      0.1      0.0      0.0386     0.0580     0.0386
32       0.1      0.1      0.0001   0.0385     0.0386     0.0385
32       0.01     0.0      0.0      0.7861     0.7800     0.7630
32       0.01     0.0      0.0001   0.7959     0.7853     0.7852
32       0.01     0.1      0.0      0.7835     0.7793     0.7665
32       0.01     0.1      0.0001   0.7810     0.7867     0.7732
32       0.001    0.0      0.0      0.8640     0.8410     0.8376
32       0.001    0.0      0.0001   0.8605     0.8435     0.8393
32       0.001    0.1      0.0      0.8536     0.8365     0.8345
32       0.001    0.1      0.0001   0.8487     0.8350     0.8318
32       0.0001   0.0      0.0      0.7914     0.7825     0.7853
32       0.0001   0.0      0.0001   0.7987     0.7882     0.7913
32       0.0001   0.1      0.0      0.7993     0.7904     0.7915
32       0.0001   0.1      0.0001   0.8007     0.7976     0.7959
64       0.1      0.0      0.0      0.0534     0.1006     0.0532
64       0.1      0.0      0.0001   0.0385     0.0556     0.0385
64       0.1      0.1      0.0      0.0385     0.0418     0.0385
64       0.1      0.1      0.0001   0.0385     0.0868     0.0385
64       0.01     0.0      0.0      0.8653     0.8330     0.8270
64       0.01     0.0      0.0001   0.8314     0.8261     0.8185
64       0.01     0.1      0.0      0.8521     0.8216     0.8185
64       0.01     0.1      0.0001   0.8119     0.8126     0.8005
64       0.001    0.0      0.0      0.9173     0.8765     0.8749
64       0.001    0.0      0.0001   0.9074     0.8788     0.8765
64       0.001    0.1      0.0      0.9006     0.8708     0.8726
64       0.001    0.1      0.0001   0.8999     0.8786     0.8763
64       0.0001   0.0      0.0      0.8629     0.8492     0.8511
64       0.0001   0.0      0.0001   0.8620     0.8479     0.8489
64       0.0001   0.1      0.0      0.8617     0.8475     0.8496
64       0.0001   0.1      0.0001   0.8619     0.8504     0.8539
128      0.1      0.0      0.0      0.0654     0.1398     0.0648
128      0.1      0.0      0.0001   0.0385     0.0502     0.0385
128      0.1      0.1      0.0      0.0385     0.0397     0.0385
128      0.1      0.1      0.0001   0.0385     0.0623     0.0385
128      0.01     0.0      0.0      0.8756     0.8380     0.8280
128      0.01     0.0      0.0001   0.8356     0.8390     0.8227
128      0.01     0.1      0.0      0.8733     0.8425     0.8298
128      0.01     0.1      0.0001   0.8331     0.8309     0.8230
128      0.001    0.0      0.0      0.9519     0.8929     0.8841
128      0.001    0.0      0.0001   0.9368     0.8956     0.8943
128      0.001    0.1      0.0      0.9435     0.8971     0.8982
128      0.001    0.1      0.0001   0.9299     0.9016     0.8982
128      0.0001   0.0      0.0      0.8999     0.8815     0.8812
128      0.0001   0.0      0.0001   0.8973     0.8811     0.8784
128      0.0001   0.1      0.0      0.8996     0.8831     0.8813
128      0.0001   0.1      0.0001   0.8963     0.8812     0.8805
256      0.1      0.0      0.0      0.0488     0.0561     0.0489
256      0.1      0.0      0.0001   0.0385     0.0534     0.0385
256      0.1      0.1      0.0      0.0385     0.0462     0.0385
256      0.1      0.1      0.0001   0.0385     0.0443     0.0385
256      0.01     0.0      0.0      0.8881     0.8489     0.8404
256      0.01     0.0      0.0001   0.8353     0.8382     0.8232
256      0.01     0.1      0.0      0.8796     0.8470     0.8400
256      0.01     0.1      0.0001   0.8352     0.8304     0.8291
256      0.001    0.0      0.0      0.9730     0.9038     0.8967
256      0.001    0.0      0.0001   0.9472     0.9060     0.8975
256      0.001    0.1      0.0      0.9627     0.9079     0.9024
256      0.001    0.1      0.0001   0.9466     0.9092     0.9050
256      0.0001   0.0      0.0      0.9258     0.8990     0.8957
256      0.0001   0.0      0.0001   0.9214     0.8979     0.8978
256      0.0001   0.1      0.0      0.9238     0.8998     0.8996
256      0.0001   0.1      0.0001   0.9212     0.9000     0.8985

================================================================================
BEST CONFIGURATION:
Hidden Size: 256, Learning Rate: 0.001, Dropout: 0.1, L2 Decay: 0.0001
Best Validation Accuracy: 0.9092
Final Test Accuracy: 0.9050
================================================================================